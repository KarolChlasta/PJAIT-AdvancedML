{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"syllable-rnn-generation.ipynb","provenance":[{"file_id":"1m8m5mSoiMrgPWvQjFcQCudYJWF9mR6Qq","timestamp":1530337993718},{"file_id":"1DztHxtFb_tfNmrLeOcav9myCNqeTlZ82","timestamp":1524492157904},{"file_id":"1sv_cPvPEWEOrG9wS3fPjAOj-Wvs6kc0P","timestamp":1524467882593}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iVsYe7S5XM5G","colab_type":"text"},"source":["![](https://i.imgur.com/eBRPvWB.png)\n","\n","# Generowanie poezji za pomocą RNN i PyTorch sylabami\n","\n","[W tutorialu na rozgrzewkę](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) użyliśmy RNN, aby sklasyfikować nazwiska znak po znaku. Tym razem wygenerujemy tekst sylaba po sylabie.\n","```\n","Litwo! Ojczyzno moja! ty jesteś klucz wyziemu, \n","To opugo cząciły tak lasu czeleta. \n","Choć nie będzie mowę świeci się za tém, \n","A Dozgon++ na Litwę przerzucił w okolicy, \n","Dosyć się opicie przyciągnąć w pałacu; \n","\n","Tamdzini nawet mimo osobnych ogórki. \n","Choć zwyciętunia, mimo pukle wyślą, \n","Odemknął, wbiegł wyszedł, pewnie miłośnik łowił. \n","Bo przekorza, i skrobiąc nabój do Warszawy. \n","Dość co oddało plecie tak fawował, \n","A tam się cukier wytaczać na nich wybująca. \n","\n","```\n","\n","Ok, możesz zadać sobie pytanie, czy ten tutorial jest rzeczywiście praktyczny? Czemu nie? Modele generatywne tego typu stanowią fundament tłumaczenia maszynowego, opisywania obrazów, generowania odpowiedzi na pytania i wielu innych zastowań.\n","\n","Zobacz [Sequence to Sequence Translation tutorial](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) żeby nauczyć się więcej w tym temacie."]},{"cell_type":"markdown","metadata":{"id":"WamMk47AXM5I","colab_type":"text"},"source":["## Polecana lektura\n","\n","Zakładam, że jest już zainstalowany PyTorch, znasz Python'a, oraz znasz pojęcie Tensor'ów:\n","\n","* http://pytorch.org/ - instalacja PyTorch\n","* [Deep Learning with PyTorch: A 60-minute Blitz](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) - Podstawy PyTorch\n","* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) przykłady wykorzystania PyTorch\n","* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) jeżeli znasz Lua Torch\n","\n","Trochę wiedzy o RNN:\n","\n","* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) przykłady z życia wzięte\n","* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) RNN i LSTM w pigułce\n","\n","Zobacz także podobne tutoriale z serii:\n","\n","* [Classifying Names with a Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) używa RNN do klasyfikacji\n","* [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb) opierając się na tym modelu, dodaje kategorię jako dane wejściowe"]},{"cell_type":"markdown","metadata":{"id":"E7PwzxO-hBJe","colab_type":"text"},"source":["## Załadowanie bibliotek"]},{"cell_type":"code","metadata":{"id":"WMhhgYDig_7G","colab_type":"code","colab":{}},"source":["from pathlib import Path\n","import platform\n","import string\n","import random\n","import re\n","from IPython.core.display import display, HTML\n","import os\n","import psutil\n","import pickle\n","import warnings\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import time, math\n","import numpy as np\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","%matplotlib inline\n","\n","import matplotlib as mpl\n","mpl.style.use('default')\n","mpl.style.use('bmh')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8KbaMvrXM5J","colab_type":"text"},"source":["## Preprocessing korpusu"]},{"cell_type":"code","metadata":{"id":"80ZjgATAXsVn","colab_type":"code","colab":{}},"source":["dataset_path = Path('data/rnn_generator'); dataset_path\n","tmp_path = dataset_path / 'tmp/'\n","!mkdir -p $tmp_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPFXCZguyyXA","colab_type":"code","outputId":"b64b3cd0-c274-46f9-a9ed-516439b416f9","executionInfo":{"status":"ok","timestamp":1570545564250,"user_tz":-120,"elapsed":4538,"user":{"displayName":"Krzysztof Wolk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDaVpXiU9tFvZLdE293ZHP_13BGqrkWUjo5c1Qiug=s64","userId":"10917561200240572409"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["ls -lah $dataset_path/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["total 12K\n","drwxr-xr-x 3 root root 4.0K Oct  8 14:39 \u001b[0m\u001b[01;34m.\u001b[0m/\n","drwxr-xr-x 3 root root 4.0K Oct  8 14:39 \u001b[01;34m..\u001b[0m/\n","drwxr-xr-x 2 root root 4.0K Oct  8 14:39 \u001b[01;34mtmp\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9eTRgNsMyyXD","colab_type":"code","colab":{}},"source":["fn_corpus_char = dataset_path/'pan_tadeusz.txt'\n","fn_corpus_caps = dataset_path/'pan_tadeusz.caps1.txt'\n","fn_corpus_syl = dataset_path/'pan_tadeusz.syl1.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wuZu6mE057C","colab_type":"text"},"source":["Plik wejściowy (korpus) to duży plik tekstowy. "]},{"cell_type":"code","metadata":{"id":"aaV5Ly3R_tzj","colab_type":"code","outputId":"0dcd825c-c66b-45bf-a298-6cf06ac9863d","executionInfo":{"status":"ok","timestamp":1570545565597,"user_tz":-120,"elapsed":5876,"user":{"displayName":"Krzysztof Wolk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDaVpXiU9tFvZLdE293ZHP_13BGqrkWUjo5c1Qiug=s64","userId":"10917561200240572409"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!head -n 21 $fn_corpus_char"],"execution_count":5,"outputs":[{"output_type":"stream","text":["head: cannot open 'data/rnn_generator/pan_tadeusz.txt' for reading: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IKPynzs-yyW-","colab_type":"text"},"source":["### Tokenizacja wielkich liter"]},{"cell_type":"markdown","metadata":{"id":"enPpQXzj_oj6","colab_type":"text"},"source":["Zamieniamy duże litery na małe dodając tokeny `_up_` (dla wyrazów pisanych wielkimi literami) lub `_cap_` (dla wyrazów pisanych z wielkiej litery)."]},{"cell_type":"code","metadata":{"id":"UJtiF_yZiA-z","colab_type":"code","colab":{}},"source":["def do_caps(ss):\n","  TOK_UP,TOK_CAP = ' _up_ ', ' _cap_ '\n","  res = []\n","  re_word = re.compile('\\w')\n","  for s in re.findall(r'\\w+|\\W+', ss):\n","      res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n","              else [TOK_CAP,s.lower()] if s.istitle()\n","              else [s.lower()])\n","  return ''.join(res)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5cAVEtNiC9X","colab_type":"code","outputId":"fc98d436-5900-4958-84af-0edd4c673c07","executionInfo":{"status":"error","timestamp":1570545566120,"user_tz":-120,"elapsed":6390,"user":{"displayName":"Krzysztof Wolk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDaVpXiU9tFvZLdE293ZHP_13BGqrkWUjo5c1Qiug=s64","userId":"10917561200240572409"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["corpus_tmp = fn_corpus_char.open('r').read()\n","corpus_tmp = do_caps(corpus_tmp)\n","fn_corpus_caps.open('w').write(corpus_tmp)"],"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f38c2cf1bb17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_corpus_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorpus_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfn_corpus_caps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         return io.open(str(self), mode, buffering, encoding, errors, newline,\n\u001b[0;32m-> 1183\u001b[0;31m                        opener=self._opener)\n\u001b[0m\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36m_opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A stub for the opener argument to built-in open()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0o777\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/rnn_generator/pan_tadeusz.txt'"]}]},{"cell_type":"code","metadata":{"id":"JJlxNo8q-quJ","colab_type":"code","colab":{}},"source":["!head -n 21 $fn_corpus_caps"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbMBLa_nxp2b","colab_type":"text"},"source":["### Podział korpusu na sylaby"]},{"cell_type":"markdown","metadata":{"id":"OONrdDyb-mS6","colab_type":"text"},"source":["Dzielimy korpus na sylaby programem `stemmer`."]},{"cell_type":"code","metadata":{"id":"efaGn-TLyyXG","colab_type":"code","colab":{}},"source":["platform_suffixes = {'Linux': 'linux', 'Darwin': 'macos'}\n","platform_suffix = platform_suffixes[platform.system()]\n","stemmer_bin = f'LD_PRELOAD=\"\" bin/stemmer.{platform_suffix}'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3qYJ20EyyXI","colab_type":"code","colab":{}},"source":["!$stemmer_bin --help\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGbQYAUYyyXK","colab_type":"code","colab":{}},"source":["!$stemmer_bin -s 7683 -v -d bin/stemmer2.dic -i $fn_corpus_caps -o $fn_corpus_syl"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rurUv5wf_135","colab_type":"code","colab":{}},"source":["!head -n 21 $fn_corpus_syl"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vpf6QibJyyXL","colab_type":"text"},"source":["### Załadowanie do pamięci i tokenizacja"]},{"cell_type":"markdown","metadata":{"id":"OSyGzgVD057R","colab_type":"text"},"source":["Ładujemy korpus do pamięci i tokenizujemy. Tworzymy też listę wszystkich tokenów `all_tokens`. Mamy już specjalne tokeny `_cap_` i `_up_`, zamieniamy znaki końca lini na token `_eol_` i dodajemy token `_unk_` na wypadek, gdybyśmy użyli sylaby (tokena), który nie wystąpił wcześniej w korpusie."]},{"cell_type":"code","metadata":{"id":"g9H83p3sXM5L","colab_type":"code","colab":{}},"source":["file = open(fn_corpus_syl).read()\n","file_len = len(file)\n","print('file_len =', file_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"maVrQMtZyyXU","colab_type":"code","colab":{}},"source":["# taken from fastai/text.py\n","\n","# remove +,- chars from punctuation set to keep syllables e.g.'--PO++' intact\n","# remove _ char to keep tokens intact\n","punctuation=re.sub('[_\\+-]', '', string.punctuation)\n","re_tok = re.compile(f'([{punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","\n","def tokenize(s, repl_unk=True): \n","  strings = re_tok.sub(r' \\1 ', s).replace('\\n', ' _eol_ ').split()\n","  if repl_unk:\n","    strings = [str2tok(s) for s in strings]\n","  return strings\n","\n","file_tok = tokenize(file, repl_unk=False); len(file_tok), file_tok[:8]\n","file_tok_len = len(file_tok)\n","\n","spec_tokens = ['_unk_', '_eol_', '_cap_', '_up_']\n","\n","all_tokens = []\n","all_tokens.extend(spec_tokens)\n","all_tokens.extend(sorted(list(set(file_tok))))\n","n_tokens = len(all_tokens); print(n_tokens, all_tokens[:50])\n","\n","tok2idx_dict = {tok: idx for (idx, tok) in enumerate(all_tokens)}\n","\n","def str2tok(str) -> int:\n","  return str if tok2idx_dict.get(str, 0) else all_tokens[0]\n","\n","def tok2idx(tok) -> int:\n","  return tok2idx_dict.get(tok, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zaNxdcoMADVS","colab_type":"text"},"source":["Przyda nam się funkcja do zakodowania dowolnego tekstu na listę zsylabizowanych tokenów:"]},{"cell_type":"code","metadata":{"id":"rDQqpRYzxT4L","colab_type":"code","colab":{}},"source":["def str2syl2tok(text):  \n","  fn_tmp_text_caps = Path(tmp_path / 'tmp_text_caps1.txt')\n","  fn_tmp_text_syl = Path(tmp_path / 'tmp_text_syl1.txt')\n","  \n","  text = do_caps(text)\n","  fn_tmp_text_caps.open('w').write(text)\n","  \n","  !$stemmer_bin -s 7683 -d bin/stemmer2.dic -i $fn_tmp_text_caps -o $fn_tmp_text_syl\n","  \n","  text_syl = fn_tmp_text_syl.open('r').read()\n","  \n","  # kill last \\n eol char possibly added by stemmer\n","  if text_syl[-1] == '\\n':\n","    text_syl = text_syl[:-1]\n","\n","  text_tok = tokenize(text_syl, repl_unk=True)\n","    \n","  return text_tok"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwnDdj75paVP","colab_type":"code","colab":{}},"source":["tekst = 'LITWO! Ojczyzno moja!\\nTy jesteś jak zdrowie.\\nIle cię trzeba cenić ble ble '\n","tekst_tok = str2syl2tok(tekst); print(tekst_tok)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bAUKI80V6CvK","colab_type":"text"},"source":["Funkcje pomocnicze do zdekodowania listy tokenów na tekst:"]},{"cell_type":"code","metadata":{"id":"JzAAi_95yyXq","colab_type":"code","colab":{}},"source":["def syl2str(a_list, delim='/'): \n","  s = ' '.join(a_list)\n","  \n","  repl_list = [\n","      ('++ --', delim), \n","  ]\n","  for repl in repl_list:\n","    s = s.replace(repl[0], repl[1])\n","  \n","  return s\n","\n","print(syl2str(tekst_tok))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUs-bnu5q2FF","colab_type":"code","colab":{}},"source":["def decode_tokens(e_str):\n","  # decode _eol_, _cap_ and _up_\n","  # leave _unk_ token alone\n","  e_syl = e_str.split(' ')\n","  e_syl2 = []\n","\n","  cap = False; up = False\n","\n","  for syl in e_syl:\n","    if syl == '_eol_': syl = '\\n'\n","\n","    if syl not in ['_cap_', '_up_']:\n","      if cap == True: syl = syl.title(); cap = False\n","      if up == True: syl = syl.upper(); up = False        \n","      e_syl2.append(syl)\n","\n","    if syl == '_cap_': cap = True\n","    if syl == '_up_': up = True\n","\n","  return ' '.join(e_syl2)\n","\n","print(decode_tokens(syl2str(tekst_tok, delim=''))[:300])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pqbQLawfrV-n","colab_type":"code","colab":{}},"source":["def fix_punctuation(s): \n","  repl_list = [\n","      ('\\n ', '\\n'), \n","      (' ,', ','),\n","      (' .', '.'),\n","      (' !', '!'),\n","      (' ?', '?'),\n","      (' ;', ';'),\n","      ('( ', '('),\n","      (' )', ')'),\n","      (' «', '«'),\n","      ('» ', '»'),\n","      (' :', ':')\n","  ]\n","  \n","  for repl in repl_list:\n","    s = s.replace(repl[0], repl[1])\n","  \n","  return s\n","\n","print(fix_punctuation(decode_tokens(syl2str(tekst_tok, delim='')))[:300])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v2VJHqQmCyuT","colab_type":"text"},"source":["Sformatujmy zdekodowany tekst w HTML i zaznaczmy na czerwono sylaby, z których nie dało się skleić słów."]},{"cell_type":"code","metadata":{"id":"WFj5nGp5yyYI","colab_type":"code","colab":{}},"source":["class X(str):\n","    def rpl(self, p, c='lightgray'):\n","        return X(self.replace(p, f'<font color=\"{c}\">{p}</font>'))\n","    def rpl2(self, p, p2):\n","        return X(self.replace(p, p2))\n","      \n","def format_html(e_str):\n","  return X(e_str).rpl('/').rpl('--', c='red').rpl('++', c='red').rpl2('\\n', '\\n<br/>')\n","\n","e_str = fix_punctuation(decode_tokens(syl2str(tekst_tok, delim='')))[:400]\n","e_html = format_html(e_str); display(HTML(e_html))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnmXGTva5nw-","colab_type":"text"},"source":["## Przygotowanie treningu"]},{"cell_type":"markdown","metadata":{"id":"2cIY0S4g0gZo","colab_type":"text"},"source":["### GPU?"]},{"cell_type":"code","metadata":{"id":"2hTjsshick9K","colab_type":"code","colab":{}},"source":["USE_GPU = torch.cuda.is_available(); \n","# USE_GPU = False; \n","\n","print(f'USE_GPU={USE_GPU}')\n","\n","def to_gpu(x, *args, **kwargs):\n","    return x.cuda(*args, **kwargs) if USE_GPU else x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5cFLx6WXM5X","colab_type":"text"},"source":["### Budowa sieci rekurencyjnej\n","\n","Ten model przyjmie jako wejściie token dla kroku $ t _ {- 1} $ i ma wyprowadzić następny token $ t $. Istnieją trzy warstwy - jedna warstwa liniowa, która koduje znak wejściowy do stanu wewnętrznego, jedna warstwa GRU (która może sama mieć wiele warstw), która działa na tym stanie wewnętrznym i stanie ukrytym, oraz warstwa dekodera, która wyprowadza rozkład prawdopodobieństwa."]},{"cell_type":"code","metadata":{"id":"tZ8chQcVXM5X","colab_type":"code","colab":{}},"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        \n","        self.encoder = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","    \n","    def forward(self, input, hidden):\n","        input = self.encoder(input.view(1, -1))\n","        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n","        output = self.decoder(output.view(1, -1))\n","        return output, hidden\n","\n","    def init_hidden(self):\n","        return Variable(to_gpu(torch.zeros(self.n_layers, 1, self.hidden_size)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62XSRFgkXM5Z","colab_type":"text"},"source":["### Tensory wejściowe i docelowe"]},{"cell_type":"markdown","metadata":{"id":"lL_XOG-fXM5T","colab_type":"text"},"source":["Aby stworzyć 'wejścia' z tego dużego ciągu danych, podzielimy go na kawałki po 400 sylab:"]},{"cell_type":"code","metadata":{"id":"_zwmRSAHXM5T","colab_type":"code","colab":{}},"source":["chunk_len = 400\n","\n","def random_chunk():\n","    start_index = random.randint(0, file_tok_len - chunk_len -1)\n","    end_index = start_index + chunk_len + 1\n","    return file_tok[start_index:end_index]\n","  \n","n_samples = file_tok_len // chunk_len; n_samples, file_tok_len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UaOPvn0rXM5Z","colab_type":"text"},"source":["Każdy 'kawałek' zostanie przekształcony w tensor, a dokładnie w `LongTensor` (używany do wartości całkowitych), poprzez przepuszczenie wszystkich tokenów ciągu i wyszukiwanie indeksu każdej sylaby w `all_tokens`."]},{"cell_type":"code","metadata":{"id":"q0H2nwMMXM5a","colab_type":"code","colab":{}},"source":["# Turn token list into list of longs\n","def tok_tensor(token_list):\n","    tensor = torch.zeros(len(token_list)).long()\n","    for c in range(len(token_list)):\n","        tensor[c] = tok2idx(token_list[c])\n","    \n","    return Variable(to_gpu(tensor))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrTEI7EjyyX2","colab_type":"code","colab":{}},"source":["tekst = 'Litwo! Ojczyzno moja! ty jesteś jak zdrowie;'\n","tekst_tok = str2syl2tok(tekst)\n","print(tekst_tok)\n","print(tok_tensor(tekst_tok))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Su49JvFXM5d","colab_type":"text"},"source":["Wreszcie możemy zmontować parę tensorów wejściowych i docelowych do treningu, z losowego kawałka. Wejściem zostaną wszystkie tokeny * aż do przedostatniego*, a celem (targetem) będą wszystkie tokeny * od drugiego*. Jeśli więc nasz kawałek to \"abc\", wejście będzie odpowiadać \"ab\", podczas gdy cel to \"bc\"."]},{"cell_type":"code","metadata":{"id":"mLzzsbTRXM5d","colab_type":"code","colab":{}},"source":["def random_training_set():  \n","    chunk = random_chunk()\n","    inp = tok_tensor(chunk[:-1])\n","    target = tok_tensor(chunk[1:])\n","    return inp, target\n","  \n","inp, target = random_training_set(); inp[:9], target[:9]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vSJ_szQTXM5f","colab_type":"text"},"source":["### Ewaluacja wyników\n","\n","Aby ocenić sieć, będziemy podawać po jednym tokenie na raz, wykorzystywać wyjścia sieci jako rozkład prawdopodobieństwa dla następnego znaku i powtarzać. Aby rozpocząć generowanie, przekazujemy ciąg wstępny, aby rozpocząć budowanie stanu ukrytego, z którego następnie generujemy po jednym tokenie na raz."]},{"cell_type":"code","metadata":{"id":"2ecqC4rWXM5f","colab_type":"code","colab":{}},"source":["def evaluate(prime_tokl=[all_tokens[1]], predict_len=100, temperature=0.8):\n","    hidden = decoder.init_hidden()\n","    prime_input = tok_tensor(prime_tokl)\n","    predicted = list(prime_tokl)  # need a copy of the list\n","\n","    # Use priming token list to \"build up\" hidden state\n","    for p in range(len(prime_tokl) - 1):\n","        _, hidden = decoder(prime_input[p], hidden)\n","    inp = prime_input[-1]\n","    \n","    for p in range(predict_len):\n","        output, hidden = decoder(inp, hidden)\n","        \n","        # Sample from the network as a multinomial distribution\n","        output_dist = output.data.view(-1).div(temperature).exp()\n","        \n","        # in pytorch 0.4.0 max, min fail if there are Infs or nans\n","        # https://github.com/pytorch/pytorch/issues/6996\n","        # in all pytorch versions multinomial fails if there are Infs or nans\n","        # https://github.com/pytorch/pytorch/issues/871\n","        # temp fix, kill Infs and nans\n","        # https://discuss.pytorch.org/t/how-to-set-inf-in-tensor-variable-to-0/10235\n","        output_dist[output_dist == float(\"Inf\")] = 0\n","        output_dist[output_dist == float(\"nan\")] = 0\n","        \n","        top_i = torch.multinomial(output_dist, 1)[0].item()\n","        \n","        # Add predicted token to the list and use as next input\n","        predicted_token = all_tokens[top_i]\n","        predicted.append(predicted_token)\n","        inp = tok_tensor([predicted_token])\n","\n","    return predicted"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZY0fPgEXM5h","colab_type":"text"},"source":["## Trening sieci"]},{"cell_type":"markdown","metadata":{"id":"-pM5T97tXM5h","colab_type":"text"},"source":["Funkcja pomocnicza do wydrukowania upływającego czasu:"]},{"cell_type":"code","metadata":{"id":"hQnLeX-TXM5h","colab_type":"code","colab":{}},"source":["def time_since(since):\n","    s = time.time() - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pntPTWEXM5i","colab_type":"text"},"source":["Główna funkcja treningowa:"]},{"cell_type":"code","metadata":{"id":"QKb7-MeXXM5j","colab_type":"code","colab":{}},"source":["def train(inp, target):\n","    hidden = decoder.init_hidden()\n","    decoder.zero_grad()\n","    loss = 0\n","\n","    for c in range(chunk_len):\n","        output, hidden = decoder(inp[c], hidden)\n","        loss += criterion(output, target[c].expand(1))\n","\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / chunk_len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2EiZtEsA0571","colab_type":"text"},"source":["Opcjonalny monitoring postępu treningu:"]},{"cell_type":"code","metadata":{"id":"HpYR9j3qyyYF","colab_type":"code","colab":{}},"source":["USE_VISDOM = False\n","\n","vis = None\n","if USE_VISDOM:\n","    import visdom\n","    vis = visdom.Visdom(port=8890)\n","\n","def vis_update_line_chart(vis, name, x, y, first_step):\n","    if not USE_VISDOM: return\n","    vis.line(Y=np.array([y]), X=np.array([x]), win=name, opts=dict(title=name),\n","             update=None if first_step else 'append')\n","\n","def vis_update_text_win(vis, name, text):\n","    if not USE_VISDOM: return\n","    vis.text(text, win=name, opts=dict(title=name), append=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5sjJFcYJDzZ2","colab_type":"text"},"source":["Wskaźnik liczby sylab, z których nie dało się skleić słów:"]},{"cell_type":"code","metadata":{"id":"tY2U1vt4yyYK","colab_type":"code","colab":{}},"source":["def bad_words(e_syl): e_str = syl2str(e_syl); return (e_str.count('++') + e_str.count('--')) / len(e_syl)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tyo69fakXM5k","colab_type":"text"},"source":["Następnie definiujemy parametry treningowe i rozpoczynamy trening:"]},{"cell_type":"code","metadata":{"id":"ILThkaRPXM5k","colab_type":"code","colab":{}},"source":["n_epochs = 15\n","n_iters = n_epochs * n_samples\n","print_every = n_samples // 2\n","plot_every = n_samples // 4\n","hidden_size = 500\n","n_layers = 3\n","lr = 0.001\n","\n","decoder = RNN(n_tokens, hidden_size, n_tokens, n_layers)\n","if USE_GPU:\n","    decoder.cuda()\n","print(decoder, flush=True)\n","\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss()\n","if USE_GPU:\n","    criterion.cuda()\n","\n","all_losses = []\n","loss_avg = 0\n","all_bw = []\n","bw_avg = 0\n","\n","iterable = range(1, n_iters + 1)\n","tqdm_ = tqdm(iterable, '', leave=False, dynamic_ncols=True, mininterval=1.0, ascii=True, miniters=1)\n","first_step = True\n","\n","prime_tok = str2syl2tok('Litwo! Ojczyzno moja!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6y2kdZUj2bw","colab_type":"code","colab":{}},"source":["start = time.time()\n","\n","for it in tqdm_:\n","    epoch = 1 + it // n_samples\n","    loss = train(*random_training_set())       \n","    loss_avg += loss\n","\n","    # current loss chart\n","    vis_update_line_chart(vis, 'loss', it, loss, it == 1)\n","\n","    # bad words    \n","    bw = bad_words(evaluate(prime_tok, 100))\n","    bw_avg += bw\n","\n","    # current bad words chart\n","    vis_update_line_chart(vis, 'bad_words', it, bw, it == 1)\n","    \n","    # progress_bar\n","    tqdm_.set_postfix({'epoch': f'{epoch}/{n_epochs}', 'loss': loss, 'bw': bw})\n","    text = f'&nbsp;<font color=\"red\">{tqdm_}</font>'\n","    vis_update_text_win(vis, 'progress_bar', text)\n","\n","    if it % print_every == 0:\n","        e_syl = evaluate(prime_tok, 1000)\n","        e_bw = bad_words(e_syl)\n","        stats_str = '\\n[%s (%d %d %d%%) loss=%.4f bw=%.4f]' % (time_since(start), epoch, it, it / n_iters * 100, loss, e_bw)\n","        print(stats_str)\n","        \n","        e_str = fix_punctuation(decode_tokens(syl2str(e_syl, delim='')))\n","        e_html = format_html(e_str); display(HTML(e_html))\n","        print(flush=True)        \n","        \n","        text = f'<b>{stats_str}</b><br />{e_html}'\n","        vis_update_text_win(vis, 'evaluation', text)\n","        \n","        e_syl_path = tmp_path / 'e_syl.txt'\n","        e_syl_path.open('w').write(' '.join(e_syl))\n","\n","    if it % plot_every == 0:\n","        vis_update_line_chart(vis, 'loss_avg', it, loss_avg / plot_every, first_step)\n","        vis_update_line_chart(vis, 'bad_words_avg', it, bw_avg / plot_every, first_step)\n","        all_bw.append(bw)\n","        bw_avg = 0\n","        first_step = False\n","        all_losses.append(loss_avg / plot_every)\n","        loss_avg = 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dXrPD94SXM5m","colab_type":"text"},"source":["### Kreślenie wartości straty\n","\n","Wykreślanie historii straty z `all_losses` pokazuje uczenie sieci:"]},{"cell_type":"code","metadata":{"id":"meKCxPo3XM5n","colab_type":"code","colab":{}},"source":["plt.figure()\n","plt.plot(all_losses)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WabkwPqZ5WlH","colab_type":"text"},"source":["### Zapis i odczyt sieci"]},{"cell_type":"markdown","metadata":{"id":"EtK-9BuuB-GX","colab_type":"text"},"source":["#### Zapisanie sieci"]},{"cell_type":"code","metadata":{"id":"aSA3Utpc6dXV","colab_type":"code","colab":{}},"source":["# n_epochs=15\n","\n","ALLTOKS, MODEL = ['all_tokens', 'model']\n","fn_pan_tadeusz = {ALLTOKS: f'all_tokens.n{n_tokens}.pan_tadeusz.p', \n","                  MODEL: f'pan_tadeusz.h{hidden_size}.l{n_layers}.e{n_epochs}.gpu.torch'}\n","fn_dict = fn_pan_tadeusz; fn_dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJ-j5_4I6d0g","colab_type":"code","colab":{}},"source":["# save all_tokens\n","all_tokens_path = tmp_path / fn_dict[ALLTOKS]\n","pickle.dump(all_tokens, open(all_tokens_path, 'wb'))\n","\n","warnings.filterwarnings('ignore')\n","\n","# save model\n","model_path = tmp_path / fn_dict[MODEL]\n","torch.save(decoder, model_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dt8_7GshWi4M","colab_type":"code","colab":{}},"source":["ls -lah $tmp_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHbGgVULB_cp","colab_type":"code","colab":{}},"source":["decoder.state_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BalhBXFKfErp","colab_type":"text"},"source":["#### Załadowanie sieci"]},{"cell_type":"code","metadata":{"id":"hk7EWQXmgfdB","colab_type":"code","colab":{}},"source":["ls -lah $tmp_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"67lBaaQ1gg3B","colab_type":"code","colab":{}},"source":["n_epochs=20\n","ALLTOKS, MODEL = ['all_tokens', 'model']\n","fn_pan_tadeusz = {ALLTOKS: f'all_tokens.n{n_tokens}.pan_tadeusz.p', \n","                  MODEL: f'pan_tadeusz.h{hidden_size}.l{n_layers}.e{n_epochs}.gpu.torch'}\n","fn_dict = fn_pan_tadeusz; fn_dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-D9_ONXNMHPK","colab_type":"code","colab":{}},"source":["if True:\n","  all_tokens_path = tmp_path / fn_dict[ALLTOKS]\n","  print(f'all_tokens_path = {all_tokens_path}')\n","  all_tokens = pickle.load(open(all_tokens_path, 'rb'))\n","  n_characters = len(all_tokens)\n","  tok2idx_dict = {tok: idx for (idx, tok) in enumerate(all_tokens)}\n","\n","  model_path = tmp_path / fn_dict[MODEL]\n","  decoder = torch.load(model_path)\n","  decoder.gru.flatten_parameters()\n","  print(f'model_path = {model_path}')\n","  print(decoder.state_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fEFWi-FXM5p","colab_type":"text"},"source":["## Ewaluacja w różnych \"temperaturach\"\n","\n","W powyższej funkcji `evaluate`, za każdym razem, gdy dokonywana jest prognoza, wyjścia są dzielone przez przekazany argument \"temperature\". Użycie większej liczby sprawia, że wszystkie akcje są bardziej jednakowo prawdopodobne, a tym samym dają nam \"bardziej losowe\" wyniki. Użycie mniejszej wartości (mniejszej niż 1) sprawia, że wysokie prawdopodobieństwa przyczyniają się bardziej. Gdy ustawiamy temperaturę na zero, wybieramy tylko najbardziej prawdopodobne wyjścia.\n","\n","Możemy zobaczyć te efekty poprzez dostosowanie argumentu `temperature`.\n"]},{"cell_type":"code","metadata":{"id":"zbRXU5j1LR3_","colab_type":"code","colab":{}},"source":["def print_eval(e_syl):\n","  display(HTML(format_html(fix_punctuation(decode_tokens(syl2str(e_syl, delim=''))))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4MTNidlS6j2","colab_type":"code","colab":{}},"source":["prime_tok = str2syl2tok('Litwo! Ojczyzno moja!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBm5ibSnXM5p","colab_type":"code","colab":{}},"source":["print_eval(evaluate(prime_tok, 200, temperature=0.8))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DnStt-FzXM5r","colab_type":"text"},"source":["Niższe temperatury daja mniejszą różnorodność, wybierając tylko bardziej prawdopodobne wyjścia:"]},{"cell_type":"code","metadata":{"id":"D3mkq_sCXM5r","colab_type":"code","colab":{}},"source":["print_eval(evaluate(prime_tok, 200, temperature=0.2))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l508QP1LXM5t","colab_type":"text"},"source":["Wyższe temperatury są bardziej różnorodne, wybierając mniej prawdopodobne wyjścia:"]},{"cell_type":"code","metadata":{"id":"SxhfgI-PXM5u","colab_type":"code","colab":{}},"source":["print_eval(evaluate(prime_tok, 200, temperature=1.4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-UQoZYk2XM5v","colab_type":"text"},"source":["## Ćwiczenia\n","\n","* Trenuj z własnym zestawem danych, np.\n","     * Tekst od innego autora\n","     * Posty na blogu\n","     * Kody źródłowe\n","* Zwiększ liczbę warstw i rozmiar sieci, aby uzyskać lepsze wyniki"]},{"cell_type":"markdown","metadata":{"id":"pFHHvkI6XM5w","colab_type":"text"},"source":["**Następnie**: [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"2tJDT2lCceZL","colab_type":"text"},"source":["## (debug) Monitorowanie maszyny wirtualnej"]},{"cell_type":"code","metadata":{"id":"bKdCiolHcg4e","colab_type":"code","colab":{}},"source":["def print_memsize():\n","  process = psutil.Process(os.getpid())\n","  print(f'{process.memory_info().rss / 1024**3:.5} GB')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"diBUUyOociRy","colab_type":"code","colab":{}},"source":["print_memsize()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TuHoo0ARtjz_","colab_type":"code","colab":{}},"source":["!uptime"],"execution_count":0,"outputs":[]}]}